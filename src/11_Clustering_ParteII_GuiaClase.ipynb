{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1hkuCNH3ErtE7kLEZQL_9Uc5eqOE-XxBv","timestamp":1716932037448},{"file_id":"1gjvQgV2x8MEgDsZt60JZSWhzT3hS49yc","timestamp":1716929540802},{"file_id":"1RuCdK0K1ekunX7a9NzAorIG6aH-KoBpN","timestamp":1716929455362}],"authorship_tag":"ABX9TyMtEi6m2oPNW9WI3cvLCpQr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Practica 3: Clustering - Parte II\n","\n","En esta segunda parte vamos a explorar algunos mecanismos para definir el número de clusters. En aplicaciones reales pocas veces tenemos esta información."],"metadata":{"id":"2FLMLMpQ1hG6"}},{"cell_type":"markdown","source":["Primero usaremos el dataset de juguete tanto para 3 como para 10 clusters que creamos en la primera parte.\n","\n"],"metadata":{"id":"qSpctmSD2VmE"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"LPpE6YTnrcdC"},"outputs":[],"source":["#Importar librerias\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from sklearn import cluster, datasets\n","from sklearn.preprocessing import StandardScaler"]},{"cell_type":"code","source":["#Generamos 500 muestras para cada dataset\n","n_samples = 500\n","seed = 30\n","#Nubes de puntos gaussianos (3 clusters)\n","blobs = datasets.make_blobs(n_samples=n_samples, random_state=seed)\n","#Nubes de puntos gaussianos (10 clusters)\n","blobs10 = datasets.make_blobs(n_samples=n_samples, centers=10, random_state=seed)"],"metadata":{"id":"JZiY9XDzr5bM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Grafica de los datasets\n","scaler = StandardScaler()\n","colors = np.array([\"#377eb8\",\n","                   \"#ff7f00\",\n","                   \"#4daf4a\",\n","                   \"#f781bf\",\n","                   \"#a65628\",\n","                   \"#984ea3\",\n","                   \"#999999\",\n","                   \"#e41a1c\",\n","                   \"#dede00\",\n","                   \"#008000\",\n","                   \"#0343DF\",\n","                   \"#7FFF00\",\n","                   \"#ED0DD9\",\n","                   \"#FBDD7E\",\n","                   \"#FFA500\"])\n","plt.figure(figsize=(15, 5))\n","\n","data_sets = [(blobs),(blobs10)]\n","i=1\n","for dataset in data_sets:\n","  X = scaler.fit_transform(dataset[0])\n","  y = dataset[1]\n","  plt.subplot(1,len(data_sets),i)\n","  plt.scatter(X[:, 0], X[:, 1],color=colors[y])\n","  i+=1"],"metadata":{"id":"FohseQRft8_k"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##K-means\n","En el caso de K-means podemos usar la suma de distancias a los centroides para establecer el número de clusters."],"metadata":{"id":"3QBQe4TvvoBQ"}},{"cell_type":"code","source":["#Importar Kmeans\n","\n","#Organizamos los datos\n","\n","#X = scaler.fit_transform(blobs10[0])\n","\n","# arreglo para la suma de distancias\n","\n","\n","#Graficamos el resultado\n"],"metadata":{"id":"l0524EfbvqHg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Usualmente se toma el final del codo vomo el valor del numero de clusters (esto tiene diferentes interpretaciones).\n","\n","Estudiemos que sucede con algunos indices de validación:\n","\n","\n","*   Davies-Bouldin: propuesta en 1979, se basa en la similaridad promedio de un cluster con su cluster más similar. Valores pequeños indican un mejor agrupamiento.\n","*   Silueta: es una medida de similitud de un punto con su cluster (cohesión) en comparación con otros clusters (separación). El valor oscila entre -1 y +1, donde un valor alto indica que los objetos estan bien cohesionados con su propio cluster y mal cohesionados con clusters vecinos.\n","\n"],"metadata":{"id":"J4C4_w33E2iA"}},{"cell_type":"code","source":["#Importamos el indice\n","\n","#Creamos un arreglo para almacenar los posibles valores\n","\n","#Valor minimo de k debe ser 2 para db\n","    #Configuramos parametros\n","\n","    #Entrenamos\n","\n","    #Almacenamos el indice\n"],"metadata":{"id":"2b7ChoZGE2Oq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Importamos el indice\n","\n","#Creamos un arreglo para almacenar los posibles valores\n","\n","    #Configuramos parametros\n","\n","    #Entrenamos\n","\n","    #Almacenamos el indice\n"],"metadata":{"id":"v1nVQo1yGX3v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["n_cluster_selected =\n","#Ingresamos número de clusters 'n_clusters'\n","#Definimos cuantas veces se repite el proceso n_init = 10 por defecto\n","\n","#Entrenamos el modelo\n","kmeans.fit(X)\n","#Obtenemos las etiquetas de pertenencia\n","y_pred_kmeans = kmeans.labels_\n","#Graficamos el resultado\n","plt.scatter(X[:, 0], X[:, 1],color=colors[y_pred_kmeans])"],"metadata":{"id":"TqnwyedBv5X5"},"execution_count":null,"outputs":[]}]}